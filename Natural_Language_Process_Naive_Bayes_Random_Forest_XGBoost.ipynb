{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Natural_Language_Process_Naive_Bayes_Random_Forest_XGBoost.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNteWGuUWFQQ7evaYvX2w8u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fauk74/Machine-Learning/blob/main/Natural_Language_Process_Naive_Bayes_Random_Forest_XGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItPuAoitC0OZ"
      },
      "source": [
        "# Natural Language Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb1xZnbsDQH-"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUKYsSy9DUUd"
      },
      "source": [
        "dataset=pd.read_csv('https://raw.githubusercontent.com/fauk74/Dataset/main/Reviews.tsv', delimiter='\\t', quoting=3)\n",
        "#to process the double quotes it will create errors: to ignore we have to add the parameter quoting=3"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RD-fr8DTb-w7",
        "outputId": "db2e922b-6293-426a-c46c-1e050c960946"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/fauk74/Data-Visualization-and-Utility/main/helper_functions.py \n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-15 18:25:48--  https://raw.githubusercontent.com/fauk74/Data-Visualization-and-Utility/main/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14292 (14K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  13.96K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-15 18:25:48 (32.3 MB/s) - ‘helper_functions.py’ saved [14292/14292]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6976ujLcQzu"
      },
      "source": [
        "from helper_functions import calculate_results"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "4su4EQwEEEcT",
        "outputId": "2be2bcc3-7e1e-4126-af3c-15f4d32f0d4e"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Liked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Liked\n",
              "0                           Wow... Loved this place.      1\n",
              "1                                 Crust is not good.      0\n",
              "2          Not tasty and the texture was just nasty.      0\n",
              "3  Stopped by during the late May bank holiday of...      1\n",
              "4  The selection on the menu was great and so wer...      1"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58Ou_j8qFY11",
        "outputId": "941cf1cf-cb42-48b5-a472-0cfbe745a244"
      },
      "source": [
        "dataset.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LQRI_KSEQXv"
      },
      "source": [
        "## Cleaning the Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH-O7yO6ES5-",
        "outputId": "020a8123-d1cb-4973-bc9d-e06119ee2108"
      },
      "source": [
        "import re \n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer \n",
        "all_stopwords=stopwords.words('english')\n",
        "all_stopwords.remove('not')\n",
        "all_stopwords.remove('no')\n",
        "\n",
        "corpus= []"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn-iCc4XFT90"
      },
      "source": [
        "for i in range(0, len(dataset)):\n",
        "  review= re.sub('[^a-zA-Z]',' ', dataset['Review'][i])\n",
        "  review=review.lower()\n",
        "  review=review.split()\n",
        "  ps=PorterStemmer()\n",
        "  review=[ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
        "  review=' '.join(review)\n",
        "  corpus.append(review)\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jecr_kHTIQD4"
      },
      "source": [
        "import random\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIZQ99wuKV41"
      },
      "source": [
        "#let's try to build a parallel corpus\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "\n",
        "\n",
        "corpus1=[]\n",
        "for i in range(0, len(dataset)):\n",
        "  review=dataset['Review'][i].lower()\n",
        "  review=tokenizer.tokenize(review)\n",
        " # ps=PorterStemmer()\n",
        " # review=[ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
        "  review=' '.join(review)\n",
        "  corpus1.append(review)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gp9zWCGmKypZ",
        "outputId": "af0b8508-8bfd-4fc3-d59e-86aad10bfc3f"
      },
      "source": [
        "#Let's explore the samples and how the 'cleaning' affected the text\n",
        "a=random.randint(0,1000)\n",
        "print(f\"Sentence n. {a}\")\n",
        "print(dataset.iloc[a][0])\n",
        "print('\\n')\n",
        "print(f\"Corpus baseline \\n{corpus[a]}\")\n",
        "print('\\n')\n",
        "print(f\"Corpus 1\\n{corpus1[a]}\")\n",
        "print(\"\\n\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence n. 997\n",
            "Overall I was not impressed and would not go back.\n",
            "\n",
            "\n",
            "Corpus baseline \n",
            "overal not impress would not go back\n",
            "\n",
            "\n",
            "Corpus 1\n",
            "overall i was not impressed and would not go back\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Eg0gIVnS7EG"
      },
      "source": [
        "# Creating the Bag of Words Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50PZb_jUKzkl"
      },
      "source": [
        "#Corpus is still in words; X is CountVectorized ; X1 is Corpu with stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer()\n",
        "X = cv.fit_transform(corpus).toarray()\n",
        "X1 = cv.fit_transform(corpus1).toarray()\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Acj9paWcUsd6",
        "outputId": "f634e108-6f8a-4d14-e724-29f62ed71548"
      },
      "source": [
        "len(X[0])"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1567"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yOgXYQrVAZI",
        "outputId": "1aac6be5-c5df-43f4-a2d2-216f43bd40c6"
      },
      "source": [
        "len(X1[0])"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2035"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdVMyARxNXGR",
        "outputId": "3b0fd633-50a5-42cb-b71c-df76b89397ef"
      },
      "source": [
        "len(corpus)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYm8bpCbNZ7j",
        "outputId": "b1f408cd-cfc0-4377-be92-9ce018b90387"
      },
      "source": [
        "corpus[:10]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wow love place',\n",
              " 'crust not good',\n",
              " 'not tasti textur nasti',\n",
              " 'stop late may bank holiday rick steve recommend love',\n",
              " 'select menu great price',\n",
              " 'get angri want damn pho',\n",
              " 'honeslti tast fresh',\n",
              " 'potato like rubber could tell made ahead time kept warmer',\n",
              " 'fri great',\n",
              " 'great touch']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQqFLWxZNjjl"
      },
      "source": [
        "y=dataset['Liked']"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dd5boNRzXo6f"
      },
      "source": [
        "#The vectorization is done before the split "
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg6RX6ByVG_8"
      },
      "source": [
        "\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UpQVxRvW8y4"
      },
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "\n"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IObt3Lm5fSeN"
      },
      "source": [
        "# Model 0: Naive Bayes Multinomial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipixkCO_WuiN",
        "outputId": "6ce76b50-8f5e-4a2d-9b9b-a7451a5da324"
      },
      "source": [
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "\n",
        "                    (\"clf\", MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(X_train, y_train)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7kYIUTSatso"
      },
      "source": [
        "y_pred=model_0.predict(X_test)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pyQKYkWYA8k",
        "outputId": "0d773d0a-c9bb-4cc9-d074-7062c45fb4ef"
      },
      "source": [
        "model_0_score = model_0.score(X_test, y_test)\n",
        "print(f\"Our baseline model Naive Bayes Multinomial achieves an accuracy of: {model_0_score*100:.2f}%\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model Naive Bayes Multinomial achieves an accuracy of: 80.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfvwanIGZ2P1",
        "outputId": "15d47526-cda5-4923-e4ff-cf2cfaeee563"
      },
      "source": [
        "model_0_results=calculate_results(y_true=y_test, \n",
        "                                  y_pred=y_pred)\n",
        "cm_0=confusion_matrix(y_test, y_pred)\n",
        "model_0_results"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 80.0, 'f1': 0.8, 'precision': 0.8, 'recall': 0.8}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yrLFySEbX2N",
        "outputId": "7e0ce09d-07a3-4428-c430-fd28eae06f4e"
      },
      "source": [
        "cm_0"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[77, 20],\n",
              "       [20, 83]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf6XMXGob37q"
      },
      "source": [
        "# Model 1: Naive Bayes Gaussian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6skot2vYYaDE",
        "outputId": "a20109da-e000-4c69-9f88-86c858437c88"
      },
      "source": [
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_1 = Pipeline([\n",
        "                    (\"clf\", GaussianNB()) # model the text\n",
        "])\n",
        "# Fit the pipeline to the training data\n",
        "model_1.fit(X_train, y_train)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('clf', GaussianNB(priors=None, var_smoothing=1e-09))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMdziZCnZYe-",
        "outputId": "0f2ea39e-b74d-4f37-8b3a-c0d81decf6bf"
      },
      "source": [
        "model_1_score = model_1.score(X_test, y_test)\n",
        "print(f\"Our  model Naive Bayes Gaussian achieves an accuracy of: {model_1_score*100:.2f}%\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our  model Naive Bayes Gaussian achieves an accuracy of: 73.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MqUWWUXZTrl",
        "outputId": "3d7c9ae8-0380-407f-d0a0-72067f525389"
      },
      "source": [
        "y_pred=model_1.predict(X_test)\n",
        "model_1_results=calculate_results(y_true=y_test, \n",
        "                                  y_pred=y_pred)\n",
        "cm_1=confusion_matrix(y_test, y_pred)\n",
        "model_1_results"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 73.0,\n",
              " 'f1': 0.722465894997933,\n",
              " 'precision': 0.7505027494108405,\n",
              " 'recall': 0.73}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITArHxMfbqfK",
        "outputId": "2c9b4eb4-dc76-4d1a-d691-0cc219d2a186"
      },
      "source": [
        "cm_1"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[55, 42],\n",
              "       [12, 91]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8KyeazteCPY"
      },
      "source": [
        "#We have to Try \n",
        "\n",
        "#CART\n",
        "\n",
        "#C5.0\n",
        "\n",
        "#Maximum Entropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwZHQhVUfnCm"
      },
      "source": [
        "# Model 2: Naive Bayes Multinomial with Corpus stopwords not removed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GplpiM7Hf0aD"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQDauPw1f-zN",
        "outputId": "f9269c02-770a-4977-d7bc-512f49ac665d"
      },
      "source": [
        "# Create  modelling pipeline\n",
        "model_2 = Pipeline([\n",
        "                    (\"clf\", MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_2.fit(X_train, y_train)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7L3PHVxgIju",
        "outputId": "e18ca01d-7211-4e10-dd99-62c9b1493764"
      },
      "source": [
        "y_pred=model_2.predict(X_test)\n",
        "model_2_results=calculate_results(y_true=y_test, \n",
        "                                  y_pred=y_pred)\n",
        "cm_2=confusion_matrix(y_test, y_pred)\n",
        "model_2_results"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 80.5,\n",
              " 'f1': 0.8050438848740967,\n",
              " 'precision': 0.80545,\n",
              " 'recall': 0.805}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DRPJW32hdWR"
      },
      "source": [
        "#We can see that not removing the stopwords we get up to 80,5% of F1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVPkkRG7iBIs"
      },
      "source": [
        "#  Model 3 Tfidvectorizer + Multinomial Naive Bayes + Corpus stopwrods not removed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-tvOR4Whmsn"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQNhouNsjqaN"
      },
      "source": [
        "# Create tokenization and modelling pipeline\n",
        "model_3 = Pipeline([\n",
        "                   (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB()) # model the text\n",
        "])\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uvwkJqroA1H"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(corpus1, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW-6zlLloZa4",
        "outputId": "ba9a8932-b57d-4fee-f90b-92a03670034f"
      },
      "source": [
        "model_3.fit(X_train, y_train)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hhFl_IyomGb",
        "outputId": "a91d0108-ffc0-416a-d466-bde3494698f9"
      },
      "source": [
        "y_pred=model_3.predict(X_test)\n",
        "model_3_results=calculate_results(y_true=y_test, \n",
        "                                  y_pred=y_pred)\n",
        "cm_3=confusion_matrix(y_test, y_pred)\n",
        "model_3_results"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.0,\n",
              " 'f1': 0.7900420168067228,\n",
              " 'precision': 0.7902420242024203,\n",
              " 'recall': 0.79}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DERl83Pio-Gw"
      },
      "source": [
        "# Model 4 Tfidvectorizer + Multinomial Naive Bayes + Corpus stopwords removed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H63vjUOIpC7r"
      },
      "source": [
        "# Create tokenization and modelling pipeline\n",
        "model_4 = Pipeline([\n",
        "                   (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB()) # model the text\n",
        "])\n"
      ],
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_ooaQ8ppQOU"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(corpus, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLQS6fiLpTGl",
        "outputId": "ebcc66d9-9093-4168-cc57-714edb4108ef"
      },
      "source": [
        "model_4.fit(X_train, y_train)"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JhFsifMpY9X",
        "outputId": "5da36c53-a4c3-45e8-e6c9-c00e7ca09f6b"
      },
      "source": [
        "y_pred=model_4.predict(X_test)\n",
        "model_4_results=calculate_results(y_true=y_test, \n",
        "                                  y_pred=y_pred)\n",
        "cm_4=confusion_matrix(y_test, y_pred)\n",
        "model_4_results"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 80.0,\n",
              " 'f1': 0.8000400160064026,\n",
              " 'precision': 0.8002400240024002,\n",
              " 'recall': 0.8}"
            ]
          },
          "metadata": {},
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmCrOprXOizy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5JG5rC-OiFa"
      },
      "source": [
        "# Model 5: Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O-hHTAkOBDs",
        "outputId": "334d0f4a-7391-45d2-966b-9327beba049f"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model_5 = RandomForestClassifier(n_estimators = 1000, criterion = 'entropy', random_state = 0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "\n",
        "model_5.fit(X_train, y_train)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='entropy', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
              "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QtlxWI6PaHF",
        "outputId": "99850a5c-9517-425e-bbdf-0b36fd452667"
      },
      "source": [
        "y_pred=model_5.predict(X_test)\n",
        "model_5_results=calculate_results(y_true=y_test, \n",
        "                                  y_pred=y_pred)\n",
        "cm_5=confusion_matrix(y_test, y_pred)\n",
        "model_5_results"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.5,\n",
              " 'f1': 0.8147454659161977,\n",
              " 'precision': 0.8194504830917875,\n",
              " 'recall': 0.815}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMyHhYbvTU7J"
      },
      "source": [
        ""
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eof-hnPmh9ms"
      },
      "source": [
        "# Model 6: XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvIpfWCzTsR3"
      },
      "source": [
        "from xgboost import XGBClassifier"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWYVaox9iFBR",
        "outputId": "a835171c-c8ac-411f-ebdc-9ac8f7d20903"
      },
      "source": [
        "model_6=XGBClassifier(n_estimators=1000)\n",
        "model_6.fit(X_train, y_train)\n",
        "\n",
        "y_pred=model_6.predict(X_test)\n",
        "model_6_results=calculate_results(y_true=y_test, \n",
        "                                  y_pred=y_pred)\n",
        "cm_6=confusion_matrix(y_test, y_pred)\n",
        "model_6_results"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.5,\n",
              " 'f1': 0.7847041901188243,\n",
              " 'precision': 0.7891847826086956,\n",
              " 'recall': 0.785}"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    }
  ]
}